#!/usr/bin/env python3
"""
JSONæ–‡ä»¶ä¸Šä¼ å’Œå¤„ç†æ¥å£
ç”¨äºå¤„ç†ä¸è§„åˆ™æˆªé¢åˆ†æçš„JSONé…ç½®æ–‡ä»¶ä¸Šä¼ ã€éªŒè¯å’Œé¢„å¤„ç†
"""

import json
import os
import sys
from typing import Dict, Any, Optional, Tuple
from pathlib import Path
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(__file__)))

from analyzer_ver1 import RCSectionAnalyzer


class JSONFileHandler:
    """JSONæ–‡ä»¶å¤„ç†ç±»"""

    def __init__(self):
        """åˆå§‹åŒ–æ–‡ä»¶å¤„ç†å™¨"""
        self.analyzer = RCSectionAnalyzer()
        self.supported_concrete_types = set(self.analyzer.CONCRETE_TYPES.keys())
        self.supported_steel_types = set(self.analyzer.STEEL_TYPES.keys())

    def validate_json_structure(self, data: Dict[str, Any]) -> Tuple[bool, str]:
        """
        éªŒè¯JSONæ–‡ä»¶ç»“æ„

        Args:
            data: è§£æåçš„JSONæ•°æ®

        Returns:
            (is_valid, error_message): éªŒè¯ç»“æœå’Œé”™è¯¯ä¿¡æ¯
        """
        try:
            # æ£€æŸ¥å¿…éœ€çš„é¡¶çº§å­—æ®µ
            required_fields = ["materials", "geometry", "reinforcement", "analysis"]
            for field in required_fields:
                if field not in data:
                    return False, f"ç¼ºå°‘å¿…éœ€å­—æ®µ: {field}"

            # éªŒè¯ææ–™ä¿¡æ¯
            materials = data["materials"]
            if "concrete_type" not in materials or "steel_type" not in materials:
                return False, "ææ–™ä¿¡æ¯ä¸å®Œæ•´"

            if materials["concrete_type"] not in self.supported_concrete_types:
                return False, f"ä¸æ”¯æŒçš„æ··å‡åœŸç±»å‹: {materials['concrete_type']}"

            if materials["steel_type"] not in self.supported_steel_types:
                return False, f"ä¸æ”¯æŒçš„é’¢ç­‹ç±»å‹: {materials['steel_type']}"

            # éªŒè¯å‡ ä½•ä¿¡æ¯
            geometry = data["geometry"]
            if "height" not in geometry or "contour_points" not in geometry:
                return False, "å‡ ä½•ä¿¡æ¯ä¸å®Œæ•´"

            if not isinstance(geometry["contour_points"], list) or len(geometry["contour_points"]) < 2:
                return False, "è½®å»“ç‚¹æ•°æ®æ— æ•ˆ"

            # éªŒè¯æ¯ä¸ªè½®å»“ç‚¹
            for i, point in enumerate(geometry["contour_points"]):
                if "y" not in point or "half_width" not in point:
                    return False, f"è½®å»“ç‚¹ {i} æ•°æ®ä¸å®Œæ•´"

            # éªŒè¯é’¢ç­‹é…ç½®
            reinforcement = data["reinforcement"]
            if "cover_thickness" not in reinforcement or "layers" not in reinforcement:
                return False, "é’¢ç­‹é…ç½®ä¿¡æ¯ä¸å®Œæ•´"

            required_layers = ["top", "middle", "bottom"]
            for layer_name in required_layers:
                if layer_name not in reinforcement["layers"]:
                    return False, f"ç¼ºå°‘é’¢ç­‹å±‚: {layer_name}"

                layer = reinforcement["layers"][layer_name]
                required_layer_fields = ["count", "diameter"]
                for field in required_layer_fields:
                    if field not in layer:
                        return False, f"é’¢ç­‹å±‚ {layer_name} ç¼ºå°‘å­—æ®µ: {field}"

            # éªŒè¯åˆ†æå‚æ•°
            analysis = data["analysis"]
            if "target_axial_force" not in analysis or "curvature_range" not in analysis:
                return False, "åˆ†æå‚æ•°ä¸å®Œæ•´"

            curvature_range = analysis["curvature_range"]
            required_range_fields = ["start", "end", "steps"]
            for field in required_range_fields:
                if field not in curvature_range:
                    return False, f"æ›²ç‡èŒƒå›´ç¼ºå°‘å­—æ®µ: {field}"

            return True, "JSONæ–‡ä»¶ç»“æ„éªŒè¯é€šè¿‡"

        except Exception as e:
            return False, f"JSONç»“æ„éªŒè¯å¤±è´¥: {str(e)}"

    def load_json_file(self, file_path: str) -> Tuple[bool, Dict[str, Any], str]:
        """
        åŠ è½½å’ŒéªŒè¯JSONæ–‡ä»¶

        Args:
            file_path: JSONæ–‡ä»¶è·¯å¾„

        Returns:
            (success, data, message): åŠ è½½ç»“æœã€æ•°æ®å’Œæ¶ˆæ¯
        """
        try:
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not os.path.exists(file_path):
                return False, {}, f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}"

            # æ£€æŸ¥æ–‡ä»¶æ‰©å±•å
            if not file_path.lower().endswith('.json'):
                return False, {}, f"æ–‡ä»¶æ ¼å¼é”™è¯¯ï¼Œåº”ä¸ºJSONæ–‡ä»¶: {file_path}"

            # æ£€æŸ¥æ–‡ä»¶å¤§å°ï¼ˆé™åˆ¶ä¸º10MBï¼‰
            file_size = os.path.getsize(file_path)
            if file_size > 10 * 1024 * 1024:
                return False, {}, f"æ–‡ä»¶è¿‡å¤§: {file_size} bytes (æœ€å¤§10MB)"

            # è¯»å–å’Œè§£æJSON
            with open(file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)

            # éªŒè¯JSONç»“æ„
            is_valid, error_msg = self.validate_json_structure(data)
            if not is_valid:
                return False, {}, f"JSONæ–‡ä»¶éªŒè¯å¤±è´¥: {error_msg}"

            logger.info(f"æˆåŠŸåŠ è½½JSONæ–‡ä»¶: {file_path}")
            return True, data, "æ–‡ä»¶åŠ è½½æˆåŠŸ"

        except json.JSONDecodeError as e:
            return False, {}, f"JSONè§£æé”™è¯¯: {str(e)}"
        except PermissionError:
            return False, {}, f"æ–‡ä»¶æƒé™é”™è¯¯ï¼Œæ— æ³•è¯»å–: {file_path}"
        except Exception as e:
            return False, {}, f"æ–‡ä»¶åŠ è½½å¤±è´¥: {str(e)}"

    def preprocess_config_data(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """
        é¢„å¤„ç†é…ç½®æ–‡ä»¶æ•°æ®ï¼Œæ·»åŠ è®¡ç®—å­—æ®µå’ŒéªŒè¯

        Args:
            data: åŸå§‹é…ç½®æ•°æ®

        Returns:
            å¤„ç†åçš„é…ç½®æ•°æ®
        """
        try:
            processed_data = data.copy()

            # è®¾ç½®ææ–™å‚æ•°å¹¶è·å–è®¡ç®—å€¼
            self.analyzer.set_materials(
                data["materials"]["concrete_type"],
                data["materials"]["steel_type"]
            )

            # æ·»åŠ ææ–™è®¡ç®—å‚æ•°
            processed_data["materials"]["calculated_params"] = {
                "f_cd": self.analyzer.f_cd,
                "f_td": self.analyzer.f_td,
                "E_c": self.analyzer.E_c,
                "epsu": self.analyzer.epsu,
                "f_yd": self.analyzer.f_yd,
                "E_s": self.analyzer.E_s
            }

            # è®¡ç®—é’¢ç­‹é¢ç§¯
            reinforcement = processed_data["reinforcement"]
            steel_areas = {}

            for layer_name, layer_info in reinforcement["layers"].items():
                count = layer_info["count"]
                diameter = layer_info["diameter"]
                area = count * 3.14159265359 * (diameter / 2) ** 2
                steel_areas[layer_name] = area

            # æ·»åŠ è®¡ç®—çš„é’¢ç­‹é¢ç§¯
            reinforcement["calculated_areas"] = steel_areas

            # éªŒè¯å‡ ä½•åˆç†æ€§
            geometry = processed_data["geometry"]
            height = geometry["height"]
            contour_points = geometry["contour_points"]

            # æ£€æŸ¥è½®å»“ç‚¹Yåæ ‡èŒƒå›´
            y_coords = [point["y"] for point in contour_points]
            if min(y_coords) != 0 or max(y_coords) != height:
                logger.warning("è½®å»“ç‚¹Yåæ ‡èŒƒå›´å¯èƒ½ä¸æ­£ç¡®")

            # æ£€æŸ¥åŠå®½åº¦åˆç†æ€§
            half_widths = [point["half_width"] for point in contour_points]
            if any(w <= 0 for w in half_widths):
                logger.warning("å‘ç°éæ­£çš„åŠå®½åº¦å€¼")

            logger.info("é…ç½®æ–‡ä»¶é¢„å¤„ç†å®Œæˆ")
            return processed_data

        except Exception as e:
            logger.error(f"é…ç½®æ–‡ä»¶é¢„å¤„ç†å¤±è´¥: {str(e)}")
            raise

    def save_processed_config(self, data: Dict[str, Any], output_path: str) -> bool:
        """
        ä¿å­˜å¤„ç†åçš„é…ç½®æ–‡ä»¶

        Args:
            data: å¤„ç†åçš„é…ç½®æ•°æ®
            output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„

        Returns:
            ä¿å­˜æ˜¯å¦æˆåŠŸ
        """
        try:
            # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
            output_dir = os.path.dirname(output_path)
            if output_dir and not os.path.exists(output_dir):
                os.makedirs(output_dir)

            # ä¿å­˜æ–‡ä»¶
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(data, f, indent=2, ensure_ascii=False)

            logger.info(f"å¤„ç†åçš„é…ç½®æ–‡ä»¶å·²ä¿å­˜: {output_path}")
            return True

        except Exception as e:
            logger.error(f"ä¿å­˜é…ç½®æ–‡ä»¶å¤±è´¥: {str(e)}")
            return False

    def get_config_summary(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """
        è·å–é…ç½®æ–‡ä»¶çš„æ‘˜è¦ä¿¡æ¯

        Args:
            data: é…ç½®æ•°æ®

        Returns:
            æ‘˜è¦ä¿¡æ¯å­—å…¸
        """
        try:
            materials = data["materials"]
            geometry = data["geometry"]
            reinforcement = data["reinforcement"]
            analysis = data["analysis"]

            # è®¡ç®—æ€»é’¢ç­‹é¢ç§¯
            total_steel_area = sum(reinforcement.get("calculated_areas", {}).values())

            summary = {
                "section_name": data.get("section_name", "æœªå‘½åæˆªé¢"),
                "description": data.get("description", ""),
                "version": data.get("version", "1.0"),
                "materials": {
                    "concrete": materials["concrete_type"],
                    "steel": materials["steel_type"]
                },
                "geometry": {
                    "height": geometry["height"],
                    "contour_points_count": len(geometry["contour_points"])
                },
                "reinforcement": {
                    "cover_thickness": reinforcement["cover_thickness"],
                    "total_steel_area": total_steel_area,
                    "layers": list(reinforcement["layers"].keys())
                },
                "analysis": {
                    "target_axial_force": analysis["target_axial_force"],
                    "curvature_range": analysis["curvature_range"]
                }
            }

            return summary

        except Exception as e:
            logger.error(f"ç”Ÿæˆé…ç½®æ‘˜è¦å¤±è´¥: {str(e)}")
            return {}


class FileUploadProcessor:
    """æ–‡ä»¶ä¸Šä¼ å¤„ç†å™¨"""

    def __init__(self, upload_dir: str = "uploads", processed_dir: str = "processed"):
        """
        åˆå§‹åŒ–æ–‡ä»¶ä¸Šä¼ å¤„ç†å™¨

        Args:
            upload_dir: ä¸Šä¼ æ–‡ä»¶ç›®å½•
            processed_dir: å¤„ç†åæ–‡ä»¶ç›®å½•
        """
        self.upload_dir = Path(upload_dir)
        self.processed_dir = Path(processed_dir)
        self.handler = JSONFileHandler()

        # åˆ›å»ºç›®å½•
        self.upload_dir.mkdir(exist_ok=True)
        self.processed_dir.mkdir(exist_ok=True)

    def process_uploaded_file(self, file_path: str) -> Dict[str, Any]:
        """
        å¤„ç†ä¸Šä¼ çš„æ–‡ä»¶

        Args:
            file_path: ä¸Šä¼ çš„æ–‡ä»¶è·¯å¾„

        Returns:
            å¤„ç†ç»“æœå­—å…¸
        """
        result = {
            "success": False,
            "message": "",
            "data": {},
            "summary": {},
            "processed_file": ""
        }

        try:
            # åŠ è½½å’ŒéªŒè¯æ–‡ä»¶
            success, data, message = self.handler.load_json_file(file_path)
            if not success:
                result["message"] = message
                return result

            # é¢„å¤„ç†æ•°æ®
            processed_data = self.handler.preprocess_config_data(data)

            # ç”Ÿæˆæ‘˜è¦
            summary = self.handler.get_config_summary(processed_data)

            # ä¿å­˜å¤„ç†åçš„æ–‡ä»¶
            filename = Path(file_path).stem
            processed_file = self.processed_dir / f"{filename}_processed.json"

            if self.handler.save_processed_config(processed_data, str(processed_file)):
                result["success"] = True
                result["message"] = "æ–‡ä»¶å¤„ç†æˆåŠŸ"
                result["data"] = processed_data
                result["summary"] = summary
                result["processed_file"] = str(processed_file)
            else:
                result["message"] = "ä¿å­˜å¤„ç†åæ–‡ä»¶å¤±è´¥"

        except Exception as e:
            result["message"] = f"æ–‡ä»¶å¤„ç†å¤±è´¥: {str(e)}"
            logger.error(f"å¤„ç†ä¸Šä¼ æ–‡ä»¶å¤±è´¥: {str(e)}")

        return result

    def get_supported_formats(self) -> Dict[str, Any]:
        """è·å–æ”¯æŒçš„æ–‡ä»¶æ ¼å¼ä¿¡æ¯"""
        return {
            "extensions": [".json"],
            "max_size": "10MB",
            "encoding": "UTF-8",
            "structure": {
                "materials": ["concrete_type", "steel_type"],
                "geometry": ["height", "contour_points"],
                "reinforcement": ["cover_thickness", "layers"],
                "analysis": ["target_axial_force", "curvature_range"]
            }
        }

    def cleanup_old_files(self, days: int = 7) -> int:
        """
        æ¸…ç†æ—§æ–‡ä»¶

        Args:
            days: ä¿ç•™å¤©æ•°

        Returns:
            åˆ é™¤çš„æ–‡ä»¶æ•°é‡
        """
        import time
        current_time = time.time()
        cutoff_time = current_time - (days * 24 * 60 * 60)

        deleted_count = 0

        # æ¸…ç†ä¸Šä¼ ç›®å½•
        for file_path in self.upload_dir.glob("*"):
            if file_path.is_file() and file_path.stat().st_mtime < cutoff_time:
                file_path.unlink()
                deleted_count += 1

        # æ¸…ç†å¤„ç†ç›®å½•
        for file_path in self.processed_dir.glob("*"):
            if file_path.is_file() and file_path.stat().st_mtime < cutoff_time:
                file_path.unlink()
                deleted_count += 1

        logger.info(f"æ¸…ç†äº† {deleted_count} ä¸ªæ—§æ–‡ä»¶")
        return deleted_count


def main():
    """ä¸»å‡½æ•°ï¼Œç”¨äºå‘½ä»¤è¡Œæµ‹è¯•"""
    import argparse

    parser = argparse.ArgumentParser(description="JSONæ–‡ä»¶ä¸Šä¼ å¤„ç†å™¨")
    parser.add_argument("file_path", help="è¦å¤„ç†çš„JSONæ–‡ä»¶è·¯å¾„")
    parser.add_argument("--output", "-o", help="è¾“å‡ºæ–‡ä»¶è·¯å¾„")
    parser.add_argument("--verbose", "-v", action="store_true", help="è¯¦ç»†è¾“å‡º")

    args = parser.parse_args()

    if args.verbose:
        logging.getLogger().setLevel(logging.DEBUG)

    # åˆ›å»ºå¤„ç†å™¨
    processor = FileUploadProcessor()

    # å¤„ç†æ–‡ä»¶
    result = processor.process_uploaded_file(args.file_path)

    if result["success"]:
        print("âœ… æ–‡ä»¶å¤„ç†æˆåŠŸ")
        print(f"ğŸ“„ æ‘˜è¦ä¿¡æ¯: {result['summary']}")

        if args.output:
            # å¦‚æœæŒ‡å®šäº†è¾“å‡ºè·¯å¾„ï¼Œå¤åˆ¶å¤„ç†åçš„æ–‡ä»¶
            import shutil
            shutil.copy2(result["processed_file"], args.output)
            print(f"ğŸ’¾ å¤„ç†åæ–‡ä»¶å·²ä¿å­˜åˆ°: {args.output}")
        else:
            print(f"ğŸ’¾ å¤„ç†åæ–‡ä»¶ä½ç½®: {result['processed_file']}")
    else:
        print(f"âŒ æ–‡ä»¶å¤„ç†å¤±è´¥: {result['message']}")
        sys.exit(1)


if __name__ == "__main__":
    main()